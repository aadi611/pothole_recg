{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f1013b",
   "metadata": {},
   "source": [
    "# üï≥Ô∏è Pothole Detection ML Model Training Notebook\n",
    "\n",
    "This notebook provides an interactive environment for training a CNN-based pothole detection model using transfer learning. We'll be usinga pre-trained models like MobileNetV2, ResNet50, and EfficientNetB0 to classify road images as containing potholes or being normal roads.\n",
    "\n",
    "## üìã What we'll cover:\n",
    "1. **Environment Setup** - Import libraries and configure settings\n",
    "2. **Data Loading & Preprocessing** - Load and prepare image data\n",
    "3. **Model Architecture** - Build CNN with transfer learning\n",
    "4. **Training Process** - Train with callbacks and monitoring\n",
    "5. **Evaluation & Metrics** - Analyze model performance\n",
    "6. **Predictions** - Test on new images\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49db41",
   "metadata": {},
   "source": [
    "## 1. üìö Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our pothole detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Check TensorFlow and GPU availability\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorFlow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKeras version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__version__\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPython version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys.version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Check GPU availability\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PotHoleRecognition\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:59\u001b[39m, in \u001b[36mLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m     58\u001b[39m   module = \u001b[38;5;28mself\u001b[39m._load()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'keras.api._v2.keras' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt0\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Computer Vision and Image Processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Machine Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, applications, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Progress bars and utilities\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check TensorFlow and GPU availability\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"üéâ GPU detected: {len(gpus)} GPU(s) available\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected. Training will use CPU (slower but still works!)\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3e7c3",
   "metadata": {},
   "source": [
    "## 2. ‚öôÔ∏è Configuration and Setup\n",
    "\n",
    "Let's define our configuration parameters and setup the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1026d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "class Config:\n",
    "    # Model parameters\n",
    "    IMG_SIZE = (224, 224)  # Input image size\n",
    "    NUM_CLASSES = 2        # Binary classification: pothole vs normal\n",
    "    CLASS_NAMES = ['normal', 'pothole']\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 30\n",
    "    LEARNING_RATE = 0.001\n",
    "    \n",
    "    # Data split ratios\n",
    "    TRAIN_RATIO = 0.7\n",
    "    VAL_RATIO = 0.2\n",
    "    TEST_RATIO = 0.1\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    MODEL_DIR = Path(\"models\")\n",
    "    RESULTS_DIR = Path(\"results\")\n",
    "    \n",
    "    # Base model options\n",
    "    BASE_MODELS = {\n",
    "        'MobileNetV2': 'Lightweight, fast inference',\n",
    "        'ResNet50': 'Good accuracy, moderate size',\n",
    "        'EfficientNetB0': 'Best accuracy/efficiency balance'\n",
    "    }\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [config.DATA_DIR, config.MODEL_DIR, config.RESULTS_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Project structure:\")\n",
    "for dir_path in [config.DATA_DIR, config.MODEL_DIR, config.RESULTS_DIR]:\n",
    "    print(f\"  ‚úì {dir_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Configuration loaded:\")\n",
    "print(f\"  Image Size: {config.IMG_SIZE}\")\n",
    "print(f\"  Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {config.EPOCHS}\")\n",
    "print(f\"  Classes: {config.CLASS_NAMES}\")\n",
    "print(f\"  Available Models: {list(config.BASE_MODELS.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
